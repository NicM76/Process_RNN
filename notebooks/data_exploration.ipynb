{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6edcabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd167e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmartin/anaconda3/envs/process/lib/python3.13/site-packages/pm4py/utils.py:1000: UserWarning: Install the optional requirement `rustxes` to import/export files faster.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b30e42c9ec4628aea03e8652d3f875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/13087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the data as dataframe\n",
    "file_path = '../data/BPI Challenge 2012_1_all/BPI_Challenge_2012.xes'\n",
    "log = pm4py.read_xes(file_path)\n",
    "df = pm4py.convert_to_dataframe(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1151db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the rows by case id and timestamp\n",
    "df = df.sort_values(by=[\"case:concept:name\", \"time:timestamp\"], ascending=True)\n",
    "df = df.drop(columns=[\"lifecycle:transition\", \"case:REG_DATE\", 'org:resource', 'case:AMOUNT_REQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e075be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A_SUBMITTED': 1, 'A_PARTLYSUBMITTED': 2, 'A_PREACCEPTED': 3, 'W_Completeren aanvraag': 4, 'A_ACCEPTED': 5, 'O_SELECTED': 6, 'A_FINALIZED': 7, 'O_CREATED': 8, 'O_SENT': 9, 'W_Nabellen offertes': 10, 'O_SENT_BACK': 11, 'W_Valideren aanvraag': 12, 'A_REGISTERED': 13, 'A_APPROVED': 14, 'O_ACCEPTED': 15, 'A_ACTIVATED': 16, 'O_CANCELLED': 17, 'W_Wijzigen contractgegevens': 18, 'A_DECLINED': 19, 'A_CANCELLED': 20, 'W_Afhandelen leads': 21, 'O_DECLINED': 22, 'W_Nabellen incomplete dossiers': 23, 'W_Beoordelen fraude': 24}\n"
     ]
    }
   ],
   "source": [
    "# create an id for every activity\n",
    "activity = df['concept:name'].unique()\n",
    "act_id = np.arange(1, len(activity) + 1)\n",
    "int_to_act = {k.item(): v for k, v in zip(act_id, activity)}\n",
    "act_to_int = dict([(value, key) for key, value in int_to_act.items()])\n",
    "print(act_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e4d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to the dataframe which desribes the activity id\n",
    "activity_id = pd.Series(act_to_int)\n",
    "df = df.merge(activity_id.to_frame(), how='left', left_on='concept:name', right_index=True)\n",
    "df = df.rename(columns={0: \"activity_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9a2cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the act_to_int dictionary as json\n",
    "with open(\"../data/activity_map.json\", \"w\") as f:\n",
    "    json.dump(act_to_int, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0cade9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>activity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.546000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.880000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-01 00:39:37.906000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 00:39:38.875000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 11:36:46.437000+00:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             concept:name                   time:timestamp case:concept:name  \\\n",
       "0             A_SUBMITTED 2011-10-01 00:38:44.546000+00:00            173688   \n",
       "1       A_PARTLYSUBMITTED 2011-10-01 00:38:44.880000+00:00            173688   \n",
       "2           A_PREACCEPTED 2011-10-01 00:39:37.906000+00:00            173688   \n",
       "3  W_Completeren aanvraag 2011-10-01 00:39:38.875000+00:00            173688   \n",
       "4  W_Completeren aanvraag 2011-10-01 11:36:46.437000+00:00            173688   \n",
       "\n",
       "   activity_id  \n",
       "0            1  \n",
       "1            2  \n",
       "2            3  \n",
       "3            4  \n",
       "4            4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c57ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X shape: (199755, 5)\n",
      "Final y shape: (199755,)\n"
     ]
    }
   ],
   "source": [
    "# Create a sequence of activities (of a certain size, here 5) for every case and take the next activity as target\n",
    "# if the sequence is less than 5, pre-pad it with zeros\n",
    "# This part was done by Gemini\n",
    "\n",
    "def create_sequences(trace, window_size=5):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        trace: A list or array of activity indices (e.g., [1, 5, 8, 2])\n",
    "        window_size: The fixed length for the model input (X)\n",
    "    Output:\n",
    "        X: List of padded sequences\n",
    "        y: List of next-step targets\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(1, len(trace)):\n",
    "        target = trace[i]          \n",
    "        history = trace[:i]       \n",
    "\n",
    "        # --- The Padding Logic ---\n",
    "        # If history is shorter than window, add 0s to the left (Pre-padding)\n",
    "        if len(history) < window_size:\n",
    "            # Formula: [0] * (missing amount) + [history]\n",
    "            padded_history = [0] * (window_size - len(history)) + list(history)\n",
    "        \n",
    "        # If history is too long, cut it and keep only the RECENT events\n",
    "        else:\n",
    "            padded_history = list(history[-window_size:])\n",
    "        \n",
    "        X.append(padded_history)\n",
    "        y.append(target)\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "# to prevent data leakage, we want to split the training and test data first, and only then we create their sequence\n",
    "# 1. Get unique Case IDs\n",
    "case_ids = df['case:concept:name'].unique()\n",
    "\n",
    "# 2. Split Case IDs (80% Train, 20% Test)\n",
    "train_cases, test_cases = train_test_split(case_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Create a boolean mask to filter the original DF\n",
    "train_df = df[df['case:concept:name'].isin(train_cases)]\n",
    "test_df = df[df['case:concept:name'].isin(test_cases)]\n",
    "\n",
    "\n",
    "# Group by Case ID\n",
    "train_grouped_activity = train_df.groupby('case:concept:name')['activity_id'].apply(list)\n",
    "test_grouped_activity = test_df.groupby('case:concept:name')['activity_id'].apply(list)\n",
    "\n",
    "# Iterate and collect\n",
    "train_X = []\n",
    "train_y = []\n",
    "test_X = []\n",
    "test_y = []\n",
    "WINDOW_SIZE = 5 \n",
    "\n",
    "for trace in train_grouped_activity:\n",
    "    X_trace, y_trace = create_sequences(trace, window_size=WINDOW_SIZE)\n",
    "    \n",
    "    # We extend the main list with the results from this trace\n",
    "    train_X.extend(X_trace)\n",
    "    train_y.extend(y_trace)\n",
    "\n",
    "for trace in test_grouped_activity:\n",
    "    X_trace, y_trace = create_sequences(trace, window_size=WINDOW_SIZE)\n",
    "    \n",
    "    # We extend the main list with the results from this trace\n",
    "    test_X.extend(X_trace)\n",
    "    test_y.extend(y_trace)\n",
    "\n",
    "# Final Conversion to Numpy (Ready for PyTorch)\n",
    "train_X = np.array(train_X)\n",
    "train_y = np.array(train_y)\n",
    "test_X = np.array(test_X)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "print(f\"Final X shape: {train_X.shape}\")\n",
    "print(f\"Final y shape: {train_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68bf748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders ready!\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to Torch tensor and create Dataloaders\n",
    "# This part was also done with Gemini\n",
    "# Convert to Tensors\n",
    "# X needs to be Long (integers) for Embedding layers\n",
    "tensor_X_train = torch.LongTensor(train_X) \n",
    "tensor_y_train = torch.LongTensor(train_y)\n",
    "\n",
    "tensor_X_test = torch.LongTensor(test_X)\n",
    "tensor_y_test = torch.LongTensor(test_y)\n",
    "\n",
    "# Wrap in TensorDataset\n",
    "train_dataset = TensorDataset(tensor_X_train, tensor_y_train)\n",
    "test_dataset = TensorDataset(tensor_X_test, tensor_y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "\n",
    "print(\"DataLoaders ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c968af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tensors\n",
    "torch.save(tensor_X_train, '../data/X_train.pt')\n",
    "torch.save(tensor_y_train, '../data/y_train.pt')\n",
    "torch.save(tensor_X_test, '../data/X_test.pt')\n",
    "torch.save(tensor_y_test, '../data/y_test.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
